import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

def learn_PCA(train_data, per_var=0.9, is_std=True):
    n, m = train_data.shape

    if is_std:
        data_mean = np.mean(train_data, axis=0)
        data_std = np.std(train_data, axis=0)
        train_data = (train_data - data_mean) / data_std
    else:
        data_mean = None
        data_std = None

    cov = np.cov(train_data.T)
    loadings, s, _ = np.linalg.svd(cov)
    latents = np.array([s])
    total_var = np.sum(latents)

    if per_var == 1:
        num_pc = m
    else:
        num_pc = np.where((np.cumsum(latents)/total_var) >= per_var)[0][0] + 1

    loadings_final = loadings[:, :num_pc]

    model = {'loadings': loadings_final,
             'data_mean': data_mean,
             'data_std': data_std}
    return model

def score_PCA(test_data, model):
    n, m = test_data.shape
    loadings = model['loadings']
    data_mean = model['data_mean']
    data_std = model['data_std']

    if data_mean is not None:
        test_data = (test_data - data_mean) / data_std

    scores_pc = np.dot(test_data, loadings)
    test_data_prime = np.dot(scores_pc, loadings.T)
    residuals = test_data - test_data_prime
    scores = np.linalg.norm(residuals, axis=1, keepdims=True)

    return scores

def learn_MS(train_data, qt=0.4):
    from sklearn.cluster import MeanShift, estimate_bandwidth

    bandwidth = estimate_bandwidth(train_data, quantile=qt)
    ms = MeanShift(bandwidth=bandwidth)
    ms.fit(train_data)
    labels = ms.labels_
    cluster_centers = ms.cluster_centers_

    labels_unique = np.unique(labels)
    n_clusters = len(labels_unique)

    print("Número de clusters estimados: %d" % n_clusters)

    model = {'n_clusters': n_clusters,
             'cluster_centers': cluster_centers,
             'labels': labels}

    return model

def score_MS(test_data, model):
    n = test_data.shape[0]
    n_clusters = model['n_clusters']
    cluster_centers = model['cluster_centers']
    scores_aux = np.zeros((n, n_clusters))

    for i in range(n_clusters):
        residuals = test_data - cluster_centers[i, :]
        scores_aux[:, i] = np.linalg.norm(residuals, axis=1)

    scores = np.min(scores_aux, axis=1)
    return scores

def detect_anomalies(scores, threshold):
    return scores > threshold

def calculate_errors(y_true, anomalies):
    tn, fp, fn, tp = confusion_matrix(y_true, anomalies).ravel()
    type_1_error = fp / (fp + tn) if (fp + tn) > 0 else 0
    type_2_error = fn / (fn + tp) if (fn + tp) > 0 else 0
    return type_1_error, type_2_error

def visualize_anomalies(data, scores, anomalies):
    plt.figure(figsize=(10, 6))
    plt.scatter(data[:, 0], data[:, 1], c=anomalies, cmap='coolwarm', label='Anomalias')
    plt.colorbar(label='Anomalias')
    plt.title('Detecção de Anomalias')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.show()
    
    
import numpy as np
from sklearn.model_selection import train_test_split

# Gerar dados sintéticos
np.random.seed(42)
X = np.random.rand(200, 2)  # 200 amostras, 2 características
y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Criar rótulos binários com base em uma condição

# Dividir os dados em conjunto de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Agora você pode usar X_train e X_test
print("Dados de treino:", X_train.shape)
print("Dados de teste:", X_test.shape)

if __name__ == "__main__":
    # Suponha que você tenha dados de treino e teste prontos
    train_data = np.random.rand(100, 2)  # Substitua pelos seus dados reais
    test_data = np.random.rand(50, 2)  # Substitua pelos seus dados reais
    y_true = np.random.randint(0, 2, size=(50,))  # Rótulos verdadeiros para os dados de teste

    # Aprender PCA
    pca_model = learn_PCA(train_data, per_var=0.9)

    # Reduzir a dimensionalidade dos dados de teste
    test_data_pca = score_PCA(test_data, pca_model)

    # Aprender o modelo Mean Shift
    ms_model = learn_MS(test_data_pca)

    # Calcular os scores para os dados de teste
    scores = score_MS(test_data_pca, ms_model)

    # Definir um threshold (ajuste conforme necessário)
    threshold = np.percentile(scores, 95)  # Usando o 95º percentil como exemplo

    # Detectar anomalias
    anomalies = detect_anomalies(scores, threshold)

    # Calcular erros tipo 1 e tipo 2
    type_1_error, type_2_error = calculate_errors(y_true, anomalies)
    print(f'Erro Tipo I: {type_1_error:.2f}')
    print(f'Erro Tipo II: {type_2_error:.2f}')

    # Visualizar anomalias
    visualize_anomalies(test_data, scores, anomalies)